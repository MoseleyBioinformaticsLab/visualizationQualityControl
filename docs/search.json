[{"path":"/LICENSE.html","id":null,"dir":"","previous_headings":"","what":"MIT License","title":"MIT License","text":"Copyright (c) 2020 Robert M Flight Hunter NB Moseley Permission hereby granted, free charge, person obtaining copy software associated documentation files (“Software”), deal Software without restriction, including without limitation rights use, copy, modify, merge, publish, distribute, sublicense, /sell copies Software, permit persons Software furnished , subject following conditions: copyright notice permission notice shall included copies substantial portions Software. SOFTWARE PROVIDED “”, WITHOUT WARRANTY KIND, EXPRESS IMPLIED, INCLUDING LIMITED WARRANTIES MERCHANTABILITY, FITNESS PARTICULAR PURPOSE NONINFRINGEMENT. EVENT SHALL AUTHORS COPYRIGHT HOLDERS LIABLE CLAIM, DAMAGES LIABILITY, WHETHER ACTION CONTRACT, TORT OTHERWISE, ARISING , CONNECTION SOFTWARE USE DEALINGS SOFTWARE.","code":""},{"path":"/articles/pca_testing.html","id":"purpose","dir":"Articles","previous_headings":"","what":"Purpose","title":"PCA Testing","text":"Principal components analysis (PCA) related methods useful data decomposition methods. However, one hundreds thousands variables many -omics methods , information beyond just examining PC1 PC2 often lost. However, may opportunities examine association sample scores principal component see associated particular sample variable interest. Following , can test loadings variables PC see significantly associated PC. variables may describe something important data doesn’t just come statistically significant differential differences.","code":""},{"path":"/articles/pca_testing.html","id":"data","dir":"Articles","previous_headings":"","what":"Data","title":"PCA Testing","text":"data use completely artificial, differences extreme completely made . 20 samples, 10 class, 1000 variables. data proportional variance structure, variance increases value. can see examining plot two columns raw log-transformed values.","code":"data(\"grp_exp_data\") data_matrix = grp_exp_data$data rownames(data_matrix) = paste0(\"f\", seq(1, nrow(data_matrix))) colnames(data_matrix) = paste0(\"s\", seq(1, ncol(data_matrix)))  sample_info <- data.frame(id = colnames(data_matrix), class = grp_exp_data$class)  dim(data_matrix) #> [1] 1000   20 data_df = as.data.frame(data_matrix[, c(1, 2)]) data_df$type = \"raw\" log_df = as.data.frame(log1p(data_matrix[, c(1, 2)])) log_df$type = \"log\"  all_df = rbind(data_df, log_df) all_df$type = factor(all_df$type, levels = c(\"raw\", \"log\"), ordered = TRUE)  ggplot(all_df, aes(x = s1, y = s2)) +   geom_point() +   facet_wrap(~ type, scales = \"free\")"},{"path":"/articles/pca_testing.html","id":"pca","dir":"Articles","previous_headings":"","what":"PCA","title":"PCA Testing","text":"use log-transformed values, PCA doesn’t well proportional variance data. can summarize variances principal component. can add scores sample info can plot sample type.  Great, class variable definitely associated PC1. variable interested knowing PC associated ?","code":"log_pca = prcomp(t(log1p(data_matrix)), center = TRUE) log_variances = visqc_score_contributions(log_pca$x) knitr::kable(log_variances) log_scores = cbind(as.data.frame(log_pca$x), sample_info) ggplot(log_scores, aes(x = PC1, y = PC2, color = class)) + geom_point()"},{"path":"/articles/pca_testing.html","id":"test-pcs","dir":"Articles","previous_headings":"","what":"Test PCs","title":"PCA Testing","text":"one PC1, lets go test anyway. artificial data-set, expect PC1 going come back something significant. can double check ANOVA results plotting scores one-dimension well.  , contrived example, things separate really, really well.","code":"pc_stats = visqc_test_pca_scores(log_pca$x, sample_info[, c(\"class\"), drop = FALSE])  knitr::kable(pc_stats) ggplot(log_scores, aes(x = PC1, fill = class)) + geom_histogram(bins = 30, position = \"identity\")"},{"path":"/articles/pca_testing.html","id":"test-loadings","dir":"Articles","previous_headings":"","what":"Test Loadings","title":"PCA Testing","text":"can also run statistical test loadings variable PC. way works construct null distribution loadings variables PCs outside current one tested. test PC1 PC2 , don’t really expect many PC2. Note large number variables, take time, slightly different null created variable excluding variables loadings PCs.","code":"loading_sig = visqc_test_pca_loadings(log_pca$rotation, test_columns = c(\"PC1\", \"PC2\"), progress = FALSE) purrr::map_dbl(loading_sig, ~ sum(.x$p.value <= 0.05)) #> PC1 PC2  #>  59  53"},{"path":"/articles/quality_control.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"Quality Control Example","text":"vignette shows various functions package can used basic quality control, addition advocating particular workflow examining experimental data prior analysis. steps consist : Principal components analysis Correlation heatmap Median correlation Feature outliers examples, compare contrast dataset composed two different conditions, dataset wherein two samples class labels switched mistake, visualizations can illustrate potential problems.","code":""},{"path":"/articles/quality_control.html","id":"data","dir":"Articles","previous_headings":"","what":"Data","title":"Quality Control Example","text":"data used simulated experiment, two classes samples. 1000 features measured, across 20 samples 2 groups, 10 group. actual values going use exp_data. classes samples defined sample_classes. also create version data two samples completely switched accident, labels , mix_data.","code":"library(visualizationQualityControl) library(ggplot2) data(grp_exp_data) exp_data <- grp_exp_data$data rownames(exp_data) <- paste0(\"f\", seq(1, nrow(exp_data))) colnames(exp_data) <- paste0(\"s\", seq(1, ncol(exp_data)))  sample_info <- data.frame(id = colnames(exp_data), class = grp_exp_data$class) sample_classes <- sample_info$class  mix_data <- exp_data mix_data[, 5] <- exp_data[, 19] mix_data[, 19] <- exp_data[, 5] str(exp_data) ##  num [1:1000, 1:20] 0.833 3.826 15.87 0.842 1.87 ... ##  - attr(*, \"dimnames\")=List of 2 ##   ..$ : chr [1:1000] \"f1\" \"f2\" \"f3\" \"f4\" ... ##   ..$ : chr [1:20] \"s1\" \"s2\" \"s3\" \"s4\" ... exp_data[1:5, 1:5] ##            s1       s2        s3        s4       s5 ## f1  0.8326984 1.795155 0.9698029  0.000000 0.000000 ## f2  3.8262483 3.103851 1.9064043  3.446350 6.217429 ## f3 15.8695770 7.078666 5.6856675 11.138222 7.580068 ## f4  0.8422794 0.000000 1.8026048  0.171272 0.000000 ## f5  1.8696869 7.724530 3.9550344  1.919573 1.087596 sample_info ##     id class ## 1   s1  grp1 ## 2   s2  grp1 ## 3   s3  grp1 ## 4   s4  grp1 ## 5   s5  grp1 ## 6   s6  grp1 ## 7   s7  grp1 ## 8   s8  grp1 ## 9   s9  grp1 ## 10 s10  grp1 ## 11 s11  grp2 ## 12 s12  grp2 ## 13 s13  grp2 ## 14 s14  grp2 ## 15 s15  grp2 ## 16 s16  grp2 ## 17 s17  grp2 ## 18 s18  grp2 ## 19 s19  grp2 ## 20 s20  grp2"},{"path":"/articles/quality_control.html","id":"data-transformation","dir":"Articles","previous_headings":"","what":"Data Transformation","title":"Quality Control Example","text":"anything else, need transform data. -omics data frequently distribution error structure many statistical methods completely choke , least give incorrect results. Make sure ask data transformed way! show raw transformed data looks like.  Notice dispersion values actual values increase. statistical methods don’t like .  , lots methods don’t deal well NA Inf values, get log-transform negative zero values. couple solutions: negatives, add negative + small offset zeros, use log1p handle zero small values methods package can handle presence NA Inf, except principal components analysis (PCA). physical data, lowest value zero. Therefore can use log1p, keep zeros zeros. Alternatively, use log1p PCA, log correlations.","code":"exp_df = as.data.frame(exp_data) ggplot(exp_df, aes(x = s1, y = s2)) + geom_point() + labs(title = \"Raw Data\") log_data <- log(exp_data) log_df = as.data.frame(log_data) ggplot(log_df, aes(x = s1, y = s2)) + geom_point() + labs(title = \"Log Transform\") log1_data <- log1p(exp_data)  small_value <- min(exp_data[exp_data != 0]) / 100 log2_data <- log2(exp_data + small_value) log_data <- log1p(exp_data) log_mix <- log1p(mix_data)"},{"path":"/articles/quality_control.html","id":"principal-components-analysis","dir":"Articles","previous_headings":"","what":"Principal Components Analysis","title":"Quality Control Example","text":"first step, use principal components analysis (PCA) decompose data. PCA trying find linear combinations original variables account maximum amount variance, finding next combination orthogonal first, . extemely useful confirming largest source variance biological one, examining confounds can explain sources variance.","code":"pca_data <- prcomp(t(log_data), center = TRUE) pca_mixed <- prcomp(t(log_mix), center = TRUE)"},{"path":"/articles/quality_control.html","id":"visualize-them","dir":"Articles","previous_headings":"Principal Components Analysis","what":"Visualize Them","title":"Quality Control Example","text":"visualize data, plot scores. want know much PC contributes variances, can get summary using visqc_score_contributions.   Note case PC1 contains large proportion variance, separates samples well. PCA plots rarely look good practice!","code":"gd_scores = cbind(as.data.frame(pca_data$x), sample_info) gd_pca = ggplot(gd_scores, aes(x = PC1, y = PC2, color = class)) + geom_point() + ggtitle(\"Good Data\") gd_pca knitr::kable(visqc_score_contributions(pca_data$x)) bad_scores = cbind(as.data.frame(pca_mixed$x), sample_info) bad_pca <- ggplot(bad_scores, aes(x = PC1, y = PC2, color = class)) + geom_point() + ggtitle(\"Bad Data\") bad_pca knitr::kable(visqc_score_contributions(pca_mixed$x))"},{"path":"/articles/quality_control.html","id":"correlation-heatmap","dir":"Articles","previous_headings":"","what":"Correlation Heatmap","title":"Quality Control Example","text":"Correlation heatmaps show much information PCA plots, different way.","code":""},{"path":"/articles/quality_control.html","id":"calculate-correlations","dir":"Articles","previous_headings":"Correlation Heatmap","what":"Calculate Correlations","title":"Quality Control Example","text":"recommend use information-content-informed Kendall-tau {ICIKendallTau::ici_kendalltau} correlation, scale invariant, includes effects missing values. Note take transpose data, function assumes data organized features columns samples rows. returns list useful information, actual correlations cor, number points correlation count, points pass various filters keep. really interested cor case. can also check right correlations looking dimensions matrix, case expect 20 20 matrix. also mixed-data.","code":"data_cor <- ICIKendallTau::ici_kendalltau(t(exp_data)) data_cor <- data_cor$cor dim(data_cor) ## [1] 20 20 mix_cor <- ICIKendallTau::ici_kendalltau(t(mix_data))$cor"},{"path":"/articles/quality_control.html","id":"reorder-correlations","dir":"Articles","previous_headings":"Correlation Heatmap","what":"Reorder Correlations","title":"Quality Control Example","text":"make heatmap useful, also clustering within sample classes reorder correlations, highlights sub-groups within classes well potential outliers.","code":"data_order <- similarity_reorderbyclass(data_cor, sample_info[, \"class\", drop = FALSE],                                         transform = \"sub_1\") mix_order <- similarity_reorderbyclass(mix_cor, sample_info[, \"class\", drop = FALSE],                                        transform = \"sub_1\")"},{"path":"/articles/quality_control.html","id":"color-by-class","dir":"Articles","previous_headings":"Correlation Heatmap","what":"Color by Class","title":"Quality Control Example","text":"also want color class.","code":"data_legend <- generate_group_colors(2) names(data_legend) <- c(\"grp1\", \"grp2\")  row_data <- sample_info[, \"class\", drop = FALSE] row_annotation <- list(class = data_legend)"},{"path":"/articles/quality_control.html","id":"map-correlation-to-color","dir":"Articles","previous_headings":"Correlation Heatmap","what":"Map Correlation to Color","title":"Quality Control Example","text":"Correlation values mapped colors using colorRamp2 function, specifying range correlations, colors map . viridis color-scale used perceptually uniform good suffering various types color blindness. choices might black -> white, color maps viridis package. information viridis available .","code":"library(viridis) library(circlize) colormap <- colorRamp2(seq(0.5, 1, length.out = 20), viridis::viridis(20))"},{"path":"/articles/quality_control.html","id":"heatmap","dir":"Articles","previous_headings":"Correlation Heatmap","what":"Heatmap!","title":"Quality Control Example","text":"Finally can make heatmaps!   Note second example, s5 s19 look odd.","code":"visqc_heatmap(data_cor, colormap, \"Good Data\", row_color_data = row_data,               row_color_list = row_annotation, col_color_data = row_data,               col_color_list = row_annotation, row_order = data_order$indices,               column_order = data_order$indices) visqc_heatmap(mix_cor, colormap, \"Bad Data\", row_color_data = row_data,               row_color_list = row_annotation, col_color_data = row_data,               col_color_list = row_annotation, row_order = mix_order$indices,               column_order = mix_order$indices)"},{"path":"/articles/quality_control.html","id":"median-correlation","dir":"Articles","previous_headings":"","what":"Median Correlation","title":"Quality Control Example","text":"Lets also calculate median correlation within class.","code":""},{"path":"/articles/quality_control.html","id":"good","dir":"Articles","previous_headings":"Median Correlation","what":"Good","title":"Quality Control Example","text":"plot using facets ggplot2.","code":"data_medcor <- median_correlations(data_cor, sample_info$class) ggplot(data_medcor, aes(x = sample_id, y = med_cor)) + geom_point() +    facet_grid(. ~ sample_class, scales = \"free\") + ggtitle(\"Good Data\")"},{"path":"/articles/quality_control.html","id":"bad","dir":"Articles","previous_headings":"Median Correlation","what":"Bad","title":"Quality Control Example","text":"Plot !","code":"mix_medcor <- median_correlations(mix_cor, sample_info$class) ggplot(mix_medcor, aes(x = sample_id, y = med_cor)) + geom_point() +   facet_grid(. ~ sample_class, scales = \"free\") + ggtitle(\"Bad Dat\")"},{"path":"/articles/quality_control.html","id":"proportion-of-outlier-features","dir":"Articles","previous_headings":"","what":"Proportion of Outlier Features","title":"Quality Control Example","text":"every feature (rows matrix), within sample-class, calculate trimmed (remove x highest lowest values) mean sd, features outside given number sd’s, calculate proportion outliers sample. Samples deviated proportion outliers examined closely. using metabolomics data large number zeros, probably want ignore zeros.","code":""},{"path":"/articles/quality_control.html","id":"good-1","dir":"Articles","previous_headings":"Proportion of Outlier Features","what":"Good","title":"Quality Control Example","text":"Plot !","code":"data_outlier <- outlier_fraction(t(log_data), sample_info$class, remove_0 = TRUE) ggplot(data_outlier, aes(x = sample_id, y = frac)) + geom_point() +    facet_grid(. ~ sample_class, scales = \"free\") + ggtitle(\"Good Data\")"},{"path":"/articles/quality_control.html","id":"bad-1","dir":"Articles","previous_headings":"Proportion of Outlier Features","what":"Bad","title":"Quality Control Example","text":"Plot .","code":"mix_outlier <- outlier_fraction(t(mix_data), sample_info$class, remove_0 = TRUE) ggplot(mix_outlier, aes(x = sample_id, y = frac)) + geom_point() +    facet_grid(. ~ sample_class, scales = \"free\") + ggtitle(\"Mix Data\")"},{"path":"/articles/quality_control.html","id":"conclusion","dir":"Articles","previous_headings":"","what":"Conclusion","title":"Quality Control Example","text":"Hopefully shown can use various tools examine high-througput -omics data potential problems.","code":""},{"path":"/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Robert M Flight. Author, maintainer. Hunter NB Moseley. Author.","code":""},{"path":"/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Flight RM, Moseley HN (2023). visualizationQualityControl: Development visualization methods quality control. R package version 0.4.11, https://moseleybioinformaticslab.github.io/visualizationQualityControlhttps://github.com/moseleybioinformaticslab/visualizationQualityControl.","code":"@Manual{,   title = {visualizationQualityControl: Development of visualization methods for quality control},   author = {Robert M Flight and Hunter NB Moseley},   year = {2023},   note = {R package version 0.4.11},   url = {https://moseleybioinformaticslab.github.io/visualizationQualityControl https://github.com/moseleybioinformaticslab/visualizationQualityControl}, }"},{"path":"/index.html","id":"visualization-quality-control","dir":"","previous_headings":"","what":"Development of visualization methods for quality control","title":"Development of visualization methods for quality control","text":"set useful functions calculating various measures high-feature datasets visualizing . addition internal documentation, package also documented heavily . package combines needs visualizing sample-sample correlations using heatmaps, novel quality control measures apply different types -omics high-feature datasets proposed Gierlinski et al., 2015, namely median_correlation outlier_fraction functions.","code":""},{"path":[]},{"path":"/index.html","id":"dependencies","dir":"","previous_headings":"Installation","what":"Dependencies","title":"Development of visualization methods for quality control","text":"ComplexHeatmap, generating heatmaps. dendsort, reordering samples heatmaps. ICIKendallTau, calculating Kendall-tau missing values. get installed automatically. recommended install BiocManager first Bioconductor dependencies installed automatically.","code":"install.packages(\"BiocManager\")"},{"path":"/index.html","id":"this-package","dir":"","previous_headings":"Installation","what":"This Package","title":"Development of visualization methods for quality control","text":"package can installed MoseleyBioinformaticsLab r-universe yet CRAN.","code":"options(repos = c(     moseleybioinformaticslab = 'https://moseleybioinformaticslab.r-universe.dev',     BiocManager::repositories())) install.packages(c(\"ICIKendallTau\", \"visualizationQualityControl\"))"},{"path":"/index.html","id":"examples","dir":"","previous_headings":"","what":"Examples","title":"Development of visualization methods for quality control","text":"examples show primary functionality. apply visualizations two group dataset. However, functions still applicable datasets two groups. examples dataset sample swapped two groups (.e. problem!). want see visualizations compare good dataset bad dataset, see quality_control vignette.","code":"library(visualizationQualityControl) library(ggplot2) library(ggforce) data(\"grp_cor_data\") exp_data = grp_cor_data$data rownames(exp_data) = paste0(\"f\", seq(1, nrow(exp_data))) colnames(exp_data) = paste0(\"s\", seq(1, ncol(exp_data)))  sample_info = data.frame(id = colnames(exp_data), class = grp_cor_data$class)  exp_data[, 5] = grp_cor_data$data[, 19] exp_data[, 19] = grp_cor_data$data[, 5] sample_classes = sample_info$class"},{"path":"/index.html","id":"visualize-pca-component-scores","dir":"","previous_headings":"Examples","what":"Visualize PCA Component Scores","title":"Development of visualization methods for quality control","text":"see much explained variance PC , can calculate :","code":"pca_data = prcomp(t(exp_data), center = TRUE) pca_scores = as.data.frame(pca_data$x) pca_scores = cbind(pca_scores, sample_info) ggplot(pca_scores, aes(x = PC1, y = PC2, color = class)) + geom_point() knitr::kable(visqc_score_contributions(pca_data$x))"},{"path":"/index.html","id":"visqc_heatmap","dir":"","previous_headings":"Examples","what":"visqc_heatmap","title":"Development of visualization methods for quality control","text":"Calculate sample-sample correlations reorder based within class correlations. recommend transform agnostic correlation like Kendall-tau can also handle missing data necessary. use {ici_kendalltau} function ICIKendallTau package. generate colormapping sample classes plot correlation heatmap.","code":"rownames(sample_info) = sample_info$sample data_cor = ICIKendallTau::ici_kendalltau(t(exp_data)) data_order = similarity_reorderbyclass(data_cor$cor, sample_info[, \"class\", drop = FALSE], transform = \"sub_1\") data_legend = generate_group_colors(2) names(data_legend) = c(\"grp1\", \"grp2\") row_data = sample_info[, \"class\", drop = FALSE] row_annotation = list(class = data_legend)  library(viridis) library(circlize) colormap = colorRamp2(seq(0.3, 1, length.out = 50), viridis::viridis(50))  visqc_heatmap(data_cor$cor, colormap, \"Correlation\", row_color_data = row_data,               row_color_list = row_annotation, col_color_data = row_data,               col_color_list = row_annotation, row_order = data_order$indices,               column_order = data_order$indices)"},{"path":"/index.html","id":"median_correlations","dir":"","previous_headings":"Examples","what":"median_correlations","title":"Development of visualization methods for quality control","text":"","code":"data_medcor = median_correlations(data_cor$cor, sample_info$class) ggplot(data_medcor, aes(x = sample_id, y = med_cor)) + geom_point() +    facet_grid(. ~ sample_class, scales = \"free_x\") + ggtitle(\"Median Correlation\") ggplot(data_medcor, aes(x = sample_class, y = med_cor)) +   geom_sina() +   ggtitle(\"Median Correlation\")"},{"path":"/index.html","id":"outlier_fraction","dir":"","previous_headings":"Examples","what":"outlier_fraction","title":"Development of visualization methods for quality control","text":"","code":"data_outlier = outlier_fraction(t(exp_data), sample_info$class) ggplot(data_outlier, aes(x = sample_id, y = frac)) + geom_point() +    facet_grid(. ~ sample_class, scales = \"free_x\") + ggtitle(\"Outlier Fraction\") ggplot(data_outlier, aes(x = sample_class, y = frac)) +   geom_sina() +   ggtitle(\"Outlier Fraction\")"},{"path":"/index.html","id":"determine_outliers","dir":"","previous_headings":"Examples","what":"determine_outliers","title":"Development of visualization methods for quality control","text":"can combine median correlations outlier fractions single score examine distribution scores look outliers.   can see outliers combined score. However, case don’t actually want remove samples. example, actually happened two samples got sample_class wrong. can see going back correlation heatmap, case high correlation values observed class samples.","code":"out_samples = determine_outliers(data_medcor, data_outlier)  ggplot(out_samples, aes(x = sample_id, y = score, color = outlier)) +   geom_point() +   facet_wrap(~ sample_class, scales = \"free_x\") +   ggtitle(\"Outliers Score\") ggplot(out_samples, aes(x = sample_class, y = score, color = outlier, group = sample_class)) +   geom_sina() +   ggtitle(\"Outliers Score\")"},{"path":"/index.html","id":"correlation-that-includes-missing-values","dir":"","previous_headings":"Examples","what":"Correlation that Includes Missing Values","title":"Development of visualization methods for quality control","text":"missing values (either NA, 0 depending case), can use information-content-informed Kendall-tau. works assumption missing data -omics samples values fall detection limit. , missingness actually contributes information can incorporated correlation. package ICIKendallTau provides correlation measure. Lets add missingness data. happens make missingness match ? counts information? feature missing samples, worth something? can see correlation sapmles S1 S2 actually increased random missing case.","code":"exp_data = grp_cor_data$data rownames(exp_data) = paste0(\"f\", seq(1, nrow(exp_data))) colnames(exp_data) = paste0(\"s\", seq(1, ncol(exp_data)))  make_na = rep(FALSE, nrow(exp_data)) s1_missing = make_na s1_missing[sample(length(make_na), 20)] = TRUE s2_missing = make_na s2_missing[sample(which(!s1_missing), 20)] = TRUE  exp_data2 = exp_data exp_data2[s1_missing, 1] = NA exp_data2[s2_missing, 1] = NA  cor_random_missing = ICIKendallTau::ici_kendalltau(t(exp_data2))$cor cor_random_missing[1:4, 1:4]  ##           s1        s2        s3        s4 ## s1 0.6000000 0.2368327 0.2315502 0.2500390 ## s2 0.2368327 1.0000000 0.7058586 0.7200000 ## s3 0.2315502 0.7058586 1.0000000 0.6925253 ## s4 0.2500390 0.7200000 0.6925253 1.0000000  cor_random_missing_nw = ICIKendallTau::ici_kendalltau(t(exp_data))$cor cor_random_missing_nw[1:4, 1:4]  ##           s1        s2        s3        s4 ## s1 1.0000000 0.6953535 0.7074747 0.7224242 ## s2 0.6953535 1.0000000 0.7058586 0.7200000 ## s3 0.7074747 0.7058586 1.0000000 0.6925253 ## s4 0.7224242 0.7200000 0.6925253 1.0000000 exp_data = grp_cor_data$data rownames(exp_data) = paste0(\"f\", seq(1, nrow(exp_data))) colnames(exp_data) = paste0(\"s\", seq(1, ncol(exp_data))) exp_data[s1_missing, 1:2] = NA  cor_same_missing = ICIKendallTau::ici_kendalltau(t(exp_data))$cor cor_same_missing[1:4, 1:4]  ##           s1        s2        s3        s4 ## s1 0.8000000 0.8050420 0.3704108 0.3778272 ## s2 0.8050420 0.8000000 0.3794753 0.3844196 ## s3 0.3704108 0.3794753 1.0000000 0.6925253 ## s4 0.3778272 0.3844196 0.6925253 1.0000000"},{"path":"/index.html","id":"fake-data-generation","dir":"","previous_headings":"","what":"Fake Data Generation","title":"Development of visualization methods for quality control","text":"fake data stored grp_cor_data useful testing median_correlation function. generated :","code":"library(fakeDataWithError) set.seed(1234)  s1 = runif(100, 0, 1) grp1 = add_uniform_noise(10, s1, 0.1)  model_data = data.frame(s1 = s1, s2 = grp1[, 1])  lm_1 = lm(s1 ~ s2, data = model_data)  lm_1$coefficients[2] = 0.5  s3 = predict(lm_1) s4 = add_uniform_noise(1, s3, 0.2)  grp2 = add_uniform_noise(10, s4, 0.1)  grp_class = rep(c(\"grp1\", \"grp2\"), each = 10)  grp_cor_data = list(data = cbind(grp1, grp2), class = grp_class)  library(fakeDataWithError) set.seed(1234)  n_point = 1000 n_rep = 10  # a nice log-normal distribution of points with points along the entire range simulated_data = c(rlnorm(n_point / 2, meanlog = 1, sdlog = 1),                     runif(n_point / 2, 5, 100))  # go to log to have decent correlations on the \"transformed\" data lsim1 = log(simulated_data)  # add some uniform noise to get lower than 1 correlations lgrp1 = add_uniform_noise(n_rep, lsim1, .5)  # add some uniform noise to everything in normal space sim1_error = add_uniform_noise(n_rep, simulated_data, 1, use_zero = TRUE) # and generate the grp1 data in normal space ngrp1 = exp(lgrp1) + sim1_error   # do regression to generate some other data model_data = data.frame(lsim1 = lsim1, lsim2 = lgrp1[, 1]) lm_1 = lm(lsim1 ~ lsim2, data = model_data)  # reduce the correlation between them lm_1$coefficients[2] = 0.5 lsim3 = predict(lm_1)  # and a bunch of error lsim4 = add_uniform_noise(1, lsim3, 1.5)  # create group with added error to reduce correlation from 1 lgrp2 = add_uniform_noise(10, lsim4, .5)  # add error in original space nsim4 = exp(lsim4) sim4_error = add_uniform_noise(10, nsim4, 1, use_zero = TRUE) ngrp2 = exp(lgrp2) + sim4_error  # put all data together, and make negatives zero all_data = cbind(ngrp1, ngrp2) all_data[(all_data < 0)] = 0  grp_class = rep(c(\"grp1\", \"grp2\"), each = 10)  grp_exp_data = list(data = all_data, class = grp_class)"},{"path":"/news/news-0.1.html","id":"visualizationqualitycontrol-011","dir":"News","previous_headings":"","what":"visualizationQualityControl 0.1.1","title":"Version 0.1","text":"Changed correlation function return list instead matrix. list contains correlations (cor), counts correlation (count), points passed criteria (keep).","code":""},{"path":"/news/news-0.2.html","id":"visualizationqualitycontrol-021","dir":"News","previous_headings":"","what":"visualizationQualityControl 0.2.1","title":"Version 0.2","text":"pairwise_correlation now uses cor internally directly, whereas previously loop allow pairwise comparisons. makes correlations 3x faster. count removed list returned pairwise_correlation new function pairwise_correlation_count get counts pairwise comparison","code":""},{"path":"/news/news-0.2.html","id":"visualizationqualitycontrol-023","dir":"News","previous_headings":"","what":"visualizationQualityControl 0.2.3","title":"Version 0.2","text":"bug discovered median_correlations meant wrong sample ids might added output data, making detection real problems difficult","code":""},{"path":"/news/news-0.2.html","id":"visualizationqualitycontrol-025","dir":"News","previous_headings":"","what":"visualizationQualityControl 0.2.5","title":"Version 0.2","text":"Added two functions, information_volume correspondence calculate weights based amount things non-zero things pairwise correlation. Added logical argument weight pairwise_correlation weight correlations. weight = TRUE, diagonal 1 anymore, instead reflect many features total sample.","code":""},{"path":"/news/news-0.2.html","id":"visualizationqualitycontrol-0218","dir":"News","previous_headings":"","what":"visualizationQualityControl 0.2.18","title":"Version 0.2","text":"Augmented correlations (weight = TRUE) much useful interpretable. information_volume correspondence calculations improved. Namely information_volume scaled maximum. correspondence default consider presence zeros samples informative, can changed setting not_both = TRUE. default useful cases lots features data sparse, zeros likely happen chance. addition returning cor matrix keep matrix, pairwise_correlations now returns raw correlations, weighting matrices info correspondence one can examined. diagonal info weighting corresponds many features sample compared sample features.","code":""},{"path":"/news/news-0.3.html","id":"visualizationqualitycontrol-030","dir":"News","previous_headings":"","what":"visualizationQualityControl 0.3.0","title":"Version 0.3","text":"median_correlations gains new argument, between_classes generate median values samples classes. causes appearance two columns set TRUE. default FALSE, hopefully cause current code misbehave, ’ve bumped version number warning.","code":""},{"path":"/news/news-0.3.html","id":"visualizationqualitycontrol-032","dir":"News","previous_headings":"","what":"visualizationQualityControl 0.3.2","title":"Version 0.3","text":"keep_non_zero_percentage gains argument, , defaults FALSE keep previous behavior. Setting = TRUE means value must non-zero least X% sample classes.","code":""},{"path":"/news/news-0.3.html","id":"visualizationqualitycontrol-0316","dir":"News","previous_headings":"","what":"visualizationQualityControl 0.3.16","title":"Version 0.3","text":"Removed requirement ggbiplot, instead added function calculating variances PCs scores. updated vignette accordingly. Now using globally_it_weighted_correlation locally_it_weighted_correlation instead pairwise_correlation.","code":""},{"path":"/news/news-0.3.html","id":"visualizationqualitycontrol-0385","dir":"News","previous_headings":"","what":"visualizationQualityControl 0.3.85","title":"Version 0.3","text":"Added function calculating information-content-informed Kendall-tau correlation, ici_kendallt, variants around calculating pairwise correlations samples; visqc_ici_kendallt visqc_ici_kendallt_splitup parallel processing.","code":""},{"path":"/news/news-0.3.html","id":"visualizationqualitycontrol-0396","dir":"News","previous_headings":"","what":"visualizationQualityControl 0.3.96","title":"Version 0.3","text":"Now throw error X Y length ici_kendallt.","code":""},{"path":"/news/news-0.3.html","id":"visualizationqualitycontrol-03100","dir":"News","previous_headings":"","what":"visualizationQualityControl 0.3.100","title":"Version 0.3","text":"Making splitup version ICI-Kendall-tau “implementation” (visqc_ici_kendallt), using single core user doesn’t setup “plan” first. reference version still exists can run tests , longer exported general users. Also inlined C++ sign function, gave us another 3X speedup 8 core machine larger test data set.","code":""},{"path":"/news/news-0.4.html","id":"visualizationqualitycontrol-040","dir":"News","previous_headings":"","what":"visualizationQualityControl 0.4.0","title":"Version 0.4","text":"Moving ICI-Kendall-tau code ’s package, ICIKendallTau. reduces dependencies necessary want run fast Kendall-tau.","code":""},{"path":"/news/news-0.4.html","id":"visualizationqualitycontrol-047","dir":"News","previous_headings":"","what":"visualizationQualityControl 0.4.7","title":"Version 0.4","text":"Updated determine_outliers able use either output median_correlations outlier_fraction singly together. using one alone, suggest explicitly naming arguments correct entry set NULL one used. Updated README show using ici_kendalltau instead it_weighted_correlation. Updated tests, moved testthat v 3. Updated pkgdown rendering help site.","code":""},{"path":"/reference/calc_sd_rsd.html","id":null,"dir":"Reference","previous_headings":"","what":"calculate values from summaries — calc_sd_rsd","title":"calculate values from summaries — calc_sd_rsd","text":"given data.frame means variances, calculate mean sd low end mean rsd high end.","code":""},{"path":"/reference/calc_sd_rsd.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"calculate values from summaries — calc_sd_rsd","text":"","code":"calc_sd_rsd(data, low_cut, hi_cut = NULL)"},{"path":"/reference/calc_sd_rsd.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"calculate values from summaries — calc_sd_rsd","text":"data data.frame means variances low_cut means <= value used average sd hi_cut means >= value used average rsd","code":""},{"path":"/reference/calc_sd_rsd.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"calculate values from summaries — calc_sd_rsd","text":"vector","code":""},{"path":"/reference/calc_sd_rsd_nls.html","id":null,"dir":"Reference","previous_headings":"","what":"calculate values from summaries v2 — calc_sd_rsd_nls","title":"calculate values from summaries v2 — calc_sd_rsd_nls","text":"given data.frame means variances, use two step non-linear least squares. first step done mean vs sd, estimates used second estimates using mean vs rsd.","code":""},{"path":"/reference/calc_sd_rsd_nls.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"calculate values from summaries v2 — calc_sd_rsd_nls","text":"","code":"calc_sd_rsd_nls(data, ...)"},{"path":"/reference/calc_sd_rsd_nls.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"calculate values from summaries v2 — calc_sd_rsd_nls","text":"data data.frame means variances ... nls parameters","code":""},{"path":"/reference/calc_sd_rsd_nls.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"calculate values from summaries v2 — calc_sd_rsd_nls","text":"vector","code":""},{"path":"/reference/calculate_fratio.html","id":null,"dir":"Reference","previous_headings":"","what":"calculate F-ratio — calculate_fratio","title":"calculate F-ratio — calculate_fratio","text":"given data matrix samples (rows) features (columns), vector classes (character factor), calculate F-ratio feature.","code":""},{"path":"/reference/calculate_fratio.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"calculate F-ratio — calculate_fratio","text":"","code":"calculate_fratio(data, data_classes)"},{"path":"/reference/calculate_fratio.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"calculate F-ratio — calculate_fratio","text":"data data matrix, samples (rows) features (columns) data_classes classes rows","code":""},{"path":"/reference/calculate_fratio.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"calculate F-ratio — calculate_fratio","text":"vector","code":""},{"path":"/reference/calculate_weights.html","id":null,"dir":"Reference","previous_headings":"","what":"calculate weights — calculate_weights","title":"calculate weights — calculate_weights","text":"calculates weights correlations","code":""},{"path":"/reference/calculate_weights.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"calculate weights — calculate_weights","text":"","code":"calculate_weights(nonzero_loc, not_both = FALSE)"},{"path":"/reference/calculate_weights.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"calculate weights — calculate_weights","text":"nonzero_loc non-zero location logical matrix not_both consider things FALSE information","code":""},{"path":"/reference/calculate_weights.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"calculate weights — calculate_weights","text":"list","code":""},{"path":"/reference/correspondence.html","id":null,"dir":"Reference","previous_headings":"","what":"correspondence — correspondence","title":"correspondence — correspondence","text":"correspondence","code":""},{"path":"/reference/correspondence.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"correspondence — correspondence","text":"","code":"correspondence(in_x, in_y, not_both = FALSE)"},{"path":"/reference/correspondence.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"correspondence — correspondence","text":"in_x things X in_y things Y not_both also include things ","code":""},{"path":"/reference/correspondence.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"correspondence — correspondence","text":"numeric","code":""},{"path":"/reference/correspondence.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"correspondence — correspondence","text":"Correspondence based many things agree compared   many things agree. default ratio things observed / things observed either handle well types data, including sparse data sets.   However, cases fact values missing   things compared counts information. alternative method   triggered setting not_both = TRUE, resulting calculation: (things observed + things observed ) / total # things value scaled largest observed correspondence weighting   well.","code":""},{"path":"/reference/count_matching_features.html","id":null,"dir":"Reference","previous_headings":"","what":"matching features — count_matching_features","title":"matching features — count_matching_features","text":"given set feature-sample matrices, calculates many features sample, well common samples, provided, common within outside sample group.","code":""},{"path":"/reference/count_matching_features.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"matching features — count_matching_features","text":"","code":"count_matching_features(feature_matrix, zero_value = NA, groups = NULL)"},{"path":"/reference/count_matching_features.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"matching features — count_matching_features","text":"feature_matrix feature sample matrix. zero_value zero value? Default NA groups groups","code":""},{"path":"/reference/count_matching_features.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"matching features — count_matching_features","text":"data.frame","code":""},{"path":"/reference/determine_outliers.html","id":null,"dir":"Reference","previous_headings":"","what":"determine outliers — determine_outliers","title":"determine outliers — determine_outliers","text":"determine outliers","code":""},{"path":"/reference/determine_outliers.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"determine outliers — determine_outliers","text":"","code":"determine_outliers(   median_correlations = NULL,   outlier_fraction = NULL,   cor_weight = 1,   frac_weight = 1,   only_high = TRUE )"},{"path":"/reference/determine_outliers.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"determine outliers — determine_outliers","text":"median_correlations median correlations outlier_fraction outlier fractions cor_weight much weight correlation score? frac_weight much weight outlier fraction? only_high things low end score removed?","code":""},{"path":"/reference/determine_outliers.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"determine outliers — determine_outliers","text":"data.frame","code":""},{"path":"/reference/determine_outliers.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"determine outliers — determine_outliers","text":"outlier sample detection, one    first generate median correlations using   `median_correlations`, outlier fractions using   `outlier_fraction`. one ,   use named arguments pass one   . Alternatively, can change weighting used median correlations   outlier fraction, including setting 0.","code":""},{"path":"/reference/filter_non_zero_percentage.html","id":null,"dir":"Reference","previous_headings":"","what":"keep features with percentage of non-zeros — filter_non_zero_percentage","title":"keep features with percentage of non-zeros — filter_non_zero_percentage","text":"Given value matrix (features columns, samples rows), sample classes,  find things zero least certain  number one classes, keep ","code":""},{"path":"/reference/filter_non_zero_percentage.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"keep features with percentage of non-zeros — filter_non_zero_percentage","text":"","code":"filter_non_zero_percentage(data_matrix, sample_classes = NULL, keep_num = 0.75)"},{"path":"/reference/filter_non_zero_percentage.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"keep features with percentage of non-zeros — filter_non_zero_percentage","text":"data_matrix matrix values work sample_classes classes sample keep_num number samples class need non-zero value (see Details)","code":""},{"path":"/reference/filter_non_zero_percentage.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"keep features with percentage of non-zeros — filter_non_zero_percentage","text":"matrix","code":""},{"path":"/reference/filter_non_zero_percentage.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"keep features with percentage of non-zeros — filter_non_zero_percentage","text":"function deprecated code use   keep_non_zero_percentage function instead.","code":""},{"path":[]},{"path":"/reference/generate_group_colors.html","id":null,"dir":"Reference","previous_headings":"","what":"create set of disjoint colors — generate_group_colors","title":"create set of disjoint colors — generate_group_colors","text":"multiple sample classes need visualized heatmap, useful able distinguish color. function generates set colors sample classes","code":""},{"path":"/reference/generate_group_colors.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"create set of disjoint colors — generate_group_colors","text":"","code":"generate_group_colors(n_group, randomize = NULL)"},{"path":"/reference/generate_group_colors.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"create set of disjoint colors — generate_group_colors","text":"n_group many groups colors randomize colors randomized? (default NULL). See details.","code":""},{"path":"/reference/generate_group_colors.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"create set of disjoint colors — generate_group_colors","text":"default randomize NULL, reordering   colors randomly decided purely based number colors requested.   Currently, cutoff 5 colors, less colors   always order, 5 colors ,   scrambled order, different time unless set.seed   used. randomize TRUE FALSE, overrides   defaults.","code":""},{"path":"/reference/globally_it_weighted_pairwise_correlation.html","id":null,"dir":"Reference","previous_headings":"","what":"globally information theoretic weighted pairwise correlation — globally_it_weighted_pairwise_correlation","title":"globally information theoretic weighted pairwise correlation — globally_it_weighted_pairwise_correlation","text":"given data matrix, calculate inter-row correlation values weighted information content information consistency.","code":""},{"path":"/reference/globally_it_weighted_pairwise_correlation.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"globally information theoretic weighted pairwise correlation — globally_it_weighted_pairwise_correlation","text":"","code":"globally_it_weighted_pairwise_correlation(   data_matrix,   use = \"pairwise.complete.obs\",   exclude_na = TRUE,   exclude_inf = TRUE,   exclude_0 = FALSE,   zero_value = 0,   method = \"pearson\",   scale_information_content = TRUE )"},{"path":"/reference/globally_it_weighted_pairwise_correlation.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"globally information theoretic weighted pairwise correlation — globally_it_weighted_pairwise_correlation","text":"data_matrix data use data use, see cor exclude_na NA values excluded (default TRUE) exclude_inf Inf values excluded (default TRUE) exclude_0 0 values excluded (default FALSE) zero_value value represents zero (default 0) method method correlation use scale_information_content information content scaled maximum value?","code":""},{"path":"/reference/globally_it_weighted_pairwise_correlation.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"globally information theoretic weighted pairwise correlation — globally_it_weighted_pairwise_correlation","text":"list","code":""},{"path":"/reference/globally_it_weighted_pairwise_correlation.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"globally information theoretic weighted pairwise correlation — globally_it_weighted_pairwise_correlation","text":"function returns named list : cor weighted correlation matrix keep logical matrix indicating points passed filtering raw raw correlations content weighting calculated information content (weighted jaccard) consistency weighted information consistency","code":""},{"path":"/reference/grp_cor.html","id":null,"dir":"Reference","previous_headings":"","what":"10 sample to sample correlations — grp_cor","title":"10 sample to sample correlations — grp_cor","text":"test data 10 sample sample correlations samples drawn two groups. Generated rmflight random distributions","code":""},{"path":"/reference/grp_cor.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"10 sample to sample correlations — grp_cor","text":"matrix 10 rows 10 columns, row colnames","code":""},{"path":"/reference/grp_cor.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"10 sample to sample correlations — grp_cor","text":"generated rmflight","code":""},{"path":"/reference/grp_cor_data.html","id":null,"dir":"Reference","previous_headings":"","what":"grp_cor_data — grp_cor_data","title":"grp_cor_data — grp_cor_data","text":"Example data used demonstrating median correlation. list 2 named entries:","code":""},{"path":"/reference/grp_cor_data.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"grp_cor_data — grp_cor_data","text":"","code":"grp_cor_data"},{"path":"/reference/grp_cor_data.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"grp_cor_data — grp_cor_data","text":"List 2 entries, data class","code":""},{"path":"/reference/grp_cor_data.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"grp_cor_data — grp_cor_data","text":"Robert M Flight","code":""},{"path":"/reference/grp_cor_data.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"grp_cor_data — grp_cor_data","text":"data data matrix 100 rows 20 columns class character vector 20 entries denoting classes data comes two groups samples, ~0.85 correlation within group, ~0.53 correlation groups.","code":""},{"path":"/reference/grp_exp_data.html","id":null,"dir":"Reference","previous_headings":"","what":"grp_exp_data — grp_exp_data","title":"grp_exp_data — grp_exp_data","text":"Example data requires log-transformation PCA QC. list 2 named entries:","code":""},{"path":"/reference/grp_exp_data.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"grp_exp_data — grp_exp_data","text":"","code":"grp_exp_data"},{"path":"/reference/grp_exp_data.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"grp_exp_data — grp_exp_data","text":"List 2 entries, data class","code":""},{"path":"/reference/grp_exp_data.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"grp_exp_data — grp_exp_data","text":"Robert M Flight","code":""},{"path":"/reference/grp_exp_data.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"grp_exp_data — grp_exp_data","text":"data data matrix 1000 rows 20 columns class character vector 20 entries denoting classes data comes two groups samples, ~0.80 correlation within group, ~0.38 correlation groups.","code":""},{"path":"/reference/grp_info.html","id":null,"dir":"Reference","previous_headings":"","what":"10 sample meta-data — grp_info","title":"10 sample meta-data — grp_info","text":"meta-data grp_cor.","code":""},{"path":"/reference/grp_info.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"10 sample meta-data — grp_info","text":"data.frame 10 rows, 2 columns, grp defining group set, defining set.","code":""},{"path":"/reference/grp_info.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"10 sample meta-data — grp_info","text":"generated rmflight","code":""},{"path":"/reference/information_volume.html","id":null,"dir":"Reference","previous_headings":"","what":"information volume — information_volume","title":"information volume — information_volume","text":"calculates information volume weight","code":""},{"path":"/reference/information_volume.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"information volume — information_volume","text":"","code":"information_volume(in_x, in_y)"},{"path":"/reference/information_volume.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"information volume — information_volume","text":"in_x things X in_y things Y","code":""},{"path":"/reference/information_volume.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"information volume — information_volume","text":"numeric","code":""},{"path":"/reference/information_volume.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"information volume — information_volume","text":"information volume based many things actually   missing samples. weighting correlations, value   scaled maximum observed value across calculated correlations.","code":""},{"path":"/reference/keep_non_zero_percentage.html","id":null,"dir":"Reference","previous_headings":"","what":"keep features with percentage of non-zeros — keep_non_zero_percentage","title":"keep features with percentage of non-zeros — keep_non_zero_percentage","text":"Given value matrix (features columns, samples rows), sample classes,  find things zero least certain  number samples one classes, keep features processing.","code":""},{"path":"/reference/keep_non_zero_percentage.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"keep features with percentage of non-zeros — keep_non_zero_percentage","text":"","code":"keep_non_zero_percentage(   data_matrix,   sample_classes = NULL,   keep_num = 0.75,   zero_value = 0,   all = FALSE )"},{"path":"/reference/keep_non_zero_percentage.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"keep features with percentage of non-zeros — keep_non_zero_percentage","text":"data_matrix matrix values work sample_classes classes sample keep_num number samples class need non-zero value (see Details) zero_value number represents zero values either / need present ?","code":""},{"path":"/reference/keep_non_zero_percentage.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"keep features with percentage of non-zeros — keep_non_zero_percentage","text":"matrix","code":""},{"path":"/reference/keep_non_zero_percentage.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"keep features with percentage of non-zeros — keep_non_zero_percentage","text":"number samples must non-zero can expressed either whole   number (greater one), fraction multiplied    number samples class get lower limits classes.","code":""},{"path":"/reference/locally_it_weighted_pairwise_correlation.html","id":null,"dir":"Reference","previous_headings":"","what":"locally information theoretic weighted pairwise correlation — locally_it_weighted_pairwise_correlation","title":"locally information theoretic weighted pairwise correlation — locally_it_weighted_pairwise_correlation","text":"given data matrix, calculate inter-row correlation values weighted information content pairwise information (jaccard index) considered.","code":""},{"path":"/reference/locally_it_weighted_pairwise_correlation.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"locally information theoretic weighted pairwise correlation — locally_it_weighted_pairwise_correlation","text":"","code":"locally_it_weighted_pairwise_correlation(   data_matrix,   use = \"pairwise.complete.obs\",   exclude_na = TRUE,   exclude_inf = TRUE,   exclude_0 = FALSE,   zero_value = 0,   method = \"pearson\" )"},{"path":"/reference/locally_it_weighted_pairwise_correlation.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"locally information theoretic weighted pairwise correlation — locally_it_weighted_pairwise_correlation","text":"data_matrix data use data use, see cor exclude_na NA values excluded (default TRUE) exclude_inf Inf values excluded (default TRUE) exclude_0 0 values excluded (default FALSE) zero_value value represents zero (default 0) method method correlation use","code":""},{"path":"/reference/locally_it_weighted_pairwise_correlation.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"locally information theoretic weighted pairwise correlation — locally_it_weighted_pairwise_correlation","text":"list","code":""},{"path":"/reference/locally_it_weighted_pairwise_correlation.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"locally information theoretic weighted pairwise correlation — locally_it_weighted_pairwise_correlation","text":"function returns named list : cor weighted correlation matrix keep logical matrix indicating points passed filtering raw raw correlations jaccard jaccard information index used weight values","code":""},{"path":"/reference/median_class_correlations.html","id":null,"dir":"Reference","previous_headings":"","what":"calculate median class correlations — median_class_correlations","title":"calculate median class correlations — median_class_correlations","text":"Given correlation matrix sample class information, calculates median correlations samples within class classes.","code":""},{"path":"/reference/median_class_correlations.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"calculate median class correlations — median_class_correlations","text":"","code":"median_class_correlations(cor_matrix, sample_classes = NULL)"},{"path":"/reference/median_class_correlations.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"calculate median class correlations — median_class_correlations","text":"cor_matrix sample - sample correlations sample_classes sample classes character factor","code":""},{"path":"/reference/median_class_correlations.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"calculate median class correlations — median_class_correlations","text":"matrix","code":""},{"path":"/reference/median_correlations.html","id":null,"dir":"Reference","previous_headings":"","what":"calculate median correlations — median_correlations","title":"calculate median correlations — median_correlations","text":"Given correlation matrix optionally sample class information, calculates median correlations sample samples class. May useful determining outliers.","code":""},{"path":"/reference/median_correlations.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"calculate median correlations — median_correlations","text":"","code":"median_correlations(cor_matrix, sample_classes = NULL, between_classes = FALSE)"},{"path":"/reference/median_correlations.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"calculate median correlations — median_correlations","text":"cor_matrix sample - sample correlations sample_classes sample classes character factor between_classes class correlations evaluated?","code":""},{"path":"/reference/median_correlations.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"calculate median correlations — median_correlations","text":"data.frame","code":""},{"path":"/reference/median_correlations.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"calculate median correlations — median_correlations","text":"data.frame may 5 columns, first three always present,   second two come between_classes = TRUE: med_cor median correlation samples sample_id sample id, either rowname index sample_class class sample. provided, set \"C1\" compare_class class sample plot_class sample_class::compare_class easy grouping","code":""},{"path":"/reference/outlier_fraction.html","id":null,"dir":"Reference","previous_headings":"","what":"fraction of outliers — outlier_fraction","title":"fraction of outliers — outlier_fraction","text":"Calculates fraction entries sample X standard deviations trimmed mean. See Details.","code":""},{"path":"/reference/outlier_fraction.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"fraction of outliers — outlier_fraction","text":"","code":"outlier_fraction(   data,   sample_classes = NULL,   n_trim = 3,   n_sd = 5,   remove_0 = FALSE )"},{"path":"/reference/outlier_fraction.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"fraction of outliers — outlier_fraction","text":"data data matrix (samples rows, columns features) sample_classes sample classes n_trim many features trim end (default 3) n_sd many SD treated outlier (default 5) remove_0 zeros removed calculating? (default FALSE)","code":""},{"path":"/reference/outlier_fraction.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"fraction of outliers — outlier_fraction","text":"data.frame","code":""},{"path":"/reference/outlier_fraction.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"fraction of outliers — outlier_fraction","text":"Based Gerlinski paper link feature (sample class), take range across samples, remove n_trim lowest highest values, calculate mean sd, actual upper lower ranges n_sd mean. sample feature, determine within outside limit. Fraction reported number features outside range. Returns data.frame : sample_id sample id, rownames used available, otherwise   index sample_class class sample sample_classes provided,   otherwise given default \"C1\" frac actual outlier fraction calculated sample","code":""},{"path":"/reference/pairwise_correlation.html","id":null,"dir":"Reference","previous_headings":"","what":"pairwise correlation — pairwise_correlation","title":"pairwise correlation — pairwise_correlation","text":"given data matrix, calculate inter-row correlation values.","code":""},{"path":"/reference/pairwise_correlation.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"pairwise correlation — pairwise_correlation","text":"","code":"pairwise_correlation(   data_matrix,   use = \"pairwise.complete.obs\",   exclude_na = TRUE,   exclude_inf = TRUE,   exclude_0 = FALSE,   zero_value = 0,   method = \"pearson\" )"},{"path":"/reference/pairwise_correlation.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"pairwise correlation — pairwise_correlation","text":"data_matrix data use data use, see cor exclude_na NA values excluded (default TRUE) exclude_inf Inf values excluded (default TRUE) exclude_0 0 values excluded (default FALSE) zero_value value represents zero (default 0) method method correlation use weight correlations weighted information content correspondence? not_both correspondence include things FALSE ?","code":""},{"path":"/reference/pairwise_correlation.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"pairwise correlation — pairwise_correlation","text":"list","code":""},{"path":"/reference/pairwise_correlation.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"pairwise correlation — pairwise_correlation","text":"function returns named list : cor correlation matrix keep logical matrix indicating points passed filtering","code":""},{"path":"/reference/pairwise_correlation_both0.html","id":null,"dir":"Reference","previous_headings":"","what":"pairwise correlation keep both zero — pairwise_correlation_both0","title":"pairwise correlation keep both zero — pairwise_correlation_both0","text":"given data matrix, calculate inter-row correlation values, entries zero, keep ","code":""},{"path":"/reference/pairwise_correlation_both0.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"pairwise correlation keep both zero — pairwise_correlation_both0","text":"","code":"pairwise_correlation_both0(   data_matrix,   use = \"pairwise\",   exclude_na = TRUE,   exclude_inf = TRUE,   exclude_0 = FALSE,   method = \"pearson\" )"},{"path":"/reference/pairwise_correlation_both0.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"pairwise correlation keep both zero — pairwise_correlation_both0","text":"data_matrix data use data use, \"pairwise\" \"complete\" exclude_na NA values excluded (default TRUE) exclude_inf Inf values excluded (default TRUE) exclude_0 0 values excluded (default FALSE) method method correlation use","code":""},{"path":"/reference/pairwise_correlation_both0.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"pairwise correlation keep both zero — pairwise_correlation_both0","text":"matrix","code":""},{"path":"/reference/pairwise_correlation_counts.html","id":null,"dir":"Reference","previous_headings":"","what":"pairwise correlation counts — pairwise_correlation_counts","title":"pairwise correlation counts — pairwise_correlation_counts","text":"given keep entry pairwise_correlation, get number things used pairwise comparisons. Note pairwise comparisons rows used.","code":""},{"path":"/reference/pairwise_correlation_counts.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"pairwise correlation counts — pairwise_correlation_counts","text":"","code":"pairwise_correlation_counts(keep_matrix)"},{"path":"/reference/pairwise_correlation_counts.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"pairwise correlation counts — pairwise_correlation_counts","text":"keep_matrix logical matrix","code":""},{"path":"/reference/pairwise_correlation_counts.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"pairwise correlation counts — pairwise_correlation_counts","text":"matrix","code":""},{"path":"/reference/pairwise_correlation_multicore.html","id":null,"dir":"Reference","previous_headings":"","what":"pairwise correlation multicore — pairwise_correlation_multicore","title":"pairwise correlation multicore — pairwise_correlation_multicore","text":"given data matrix, calculate inter-row correlation values","code":""},{"path":"/reference/pairwise_correlation_multicore.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"pairwise correlation multicore — pairwise_correlation_multicore","text":"","code":"pairwise_correlation_multicore(   data_matrix,   use = \"pairwise\",   exclude_na = TRUE,   exclude_inf = TRUE,   exclude_0 = FALSE,   method = \"pearson\" )"},{"path":"/reference/pairwise_correlation_multicore.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"pairwise correlation multicore — pairwise_correlation_multicore","text":"data_matrix data use data use, \"pairwise\" \"complete\" exclude_na NA values excluded (default TRUE) exclude_inf Inf values excluded (default TRUE) exclude_0 0 values excluded (default FALSE) method method correlation use","code":""},{"path":"/reference/pairwise_correlation_multicore.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"pairwise correlation multicore — pairwise_correlation_multicore","text":"matrix","code":""},{"path":"/reference/pairwise_distance.html","id":null,"dir":"Reference","previous_headings":"","what":"pairwise distance — pairwise_distance","title":"pairwise distance — pairwise_distance","text":"given data matrix, calculate inter-row distances","code":""},{"path":"/reference/pairwise_distance.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"pairwise distance — pairwise_distance","text":"","code":"pairwise_distance(   data_matrix,   use = \"pairwise\",   exclude_na = TRUE,   exclude_inf = TRUE,   exclude_0 = FALSE )"},{"path":"/reference/pairwise_distance.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"pairwise distance — pairwise_distance","text":"data_matrix data use data use, \"pairwise\" \"complete\" exclude_na NA values excluded (default TRUE) exclude_inf Inf values excluded (default TRUE) exclude_0 0 values excluded (default FALSE)","code":""},{"path":"/reference/pairwise_distance.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"pairwise distance — pairwise_distance","text":"matrix","code":""},{"path":"/reference/pairwise_nonzero.html","id":null,"dir":"Reference","previous_headings":"","what":"pairwise non-zero — pairwise_nonzero","title":"pairwise non-zero — pairwise_nonzero","text":"given data matrix, many entries non-zero pairwise basis","code":""},{"path":"/reference/pairwise_nonzero.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"pairwise non-zero — pairwise_nonzero","text":"","code":"pairwise_nonzero(   data_matrix,   use = \"pairwise\",   exclude_na = TRUE,   exclude_inf = TRUE )"},{"path":"/reference/pairwise_nonzero.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"pairwise non-zero — pairwise_nonzero","text":"data_matrix data use work data exclude_na NA values excluded (default TRUE) exclude_inf Inf values excluded (default TRUE)","code":""},{"path":"/reference/pairwise_nonzero.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"pairwise non-zero — pairwise_nonzero","text":"matrix","code":""},{"path":"/reference/pipe.html","id":null,"dir":"Reference","previous_headings":"","what":"Pipe operator — %>%","title":"Pipe operator — %>%","text":"See magrittr::%>% details.","code":""},{"path":"/reference/pipe.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Pipe operator — %>%","text":"","code":"lhs %>% rhs"},{"path":"/reference/pipe.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Pipe operator — %>%","text":"lhs value magrittr placeholder. rhs function call using magrittr semantics.","code":""},{"path":"/reference/pipe.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Pipe operator — %>%","text":"result calling `rhs(lhs)`.","code":""},{"path":"/reference/similarity_reorder.html","id":null,"dir":"Reference","previous_headings":"","what":"cluster and reorder — similarity_reorder","title":"cluster and reorder — similarity_reorder","text":"given matrix (maybe distance matrix), cluster re-order using dendsort.","code":""},{"path":"/reference/similarity_reorder.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"cluster and reorder — similarity_reorder","text":"","code":"similarity_reorder(   similarity_matrix,   matrix_indices = NULL,   transform = \"none\",   hclust_method = \"complete\",   dendsort_type = \"min\" )"},{"path":"/reference/similarity_reorder.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"cluster and reorder — similarity_reorder","text":"similarity_matrix matrix similarities matrix_indices indices reorder transform transformation applied data first hclust_method method clustering used? dendsort_type reordering done? (default \"min\")","code":""},{"path":"/reference/similarity_reorder.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"cluster and reorder — similarity_reorder","text":"dendrogram object. get order use order.dendogram.","code":""},{"path":"/reference/similarity_reorderbyclass.html","id":null,"dir":"Reference","previous_headings":"","what":"reorder by sample class — similarity_reorderbyclass","title":"reorder by sample class — similarity_reorderbyclass","text":"avoid spurious visualization problems, useful heatmap visualization reorder samples within sample class. function uses  hierarchical clustering dendsort sort entries distance matrix.","code":""},{"path":"/reference/similarity_reorderbyclass.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"reorder by sample class — similarity_reorderbyclass","text":"","code":"similarity_reorderbyclass(   similarity_matrix,   sample_classes = NULL,   transform = \"none\",   hclust_method = \"complete\",   dendsort_type = \"min\" )"},{"path":"/reference/similarity_reorderbyclass.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"reorder by sample class — similarity_reorderbyclass","text":"similarity_matrix matrix similarities objects sample_classes data.frame factor denoting classes transform transformation apply data hclust_method method clustering used dendsort_type dendsort reordering?","code":""},{"path":"/reference/similarity_reorderbyclass.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"reorder by sample class — similarity_reorderbyclass","text":"list containing reordering matrix :  dendrogram numeric vector character vector (NULL rownames set matrix)","code":""},{"path":"/reference/similarity_reorderbyclass.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"reorder by sample class — similarity_reorderbyclass","text":"similarity_matrix either square matrix similarity values distance matrix class dist. matrix encode \"true\" distance, can use transform turn true distance (example, correlation, distance 1 - correlation, use \"sub_1\" transform argument). sample_classes either data.frame factor argument.  data.frame passed, columns data.frame pasted together create factor splitting data groups. rownames data.frame correspond rownames colnames matrix, assumed ordering matrix data.frame identical.","code":""},{"path":"/reference/similarity_reorderbyclass.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"reorder by sample class — similarity_reorderbyclass","text":"","code":"library(visualizationQualityControl) set.seed(1234) mat <- matrix(rnorm(100, 2, sd = 0.5), 10, 10) rownames(mat) <- colnames(mat) <- letters[1:10] neworder <- similarity_reorderbyclass(mat) mat[neworder$indices, neworder$indices] #>           a         d        g        b        c        f        e        h #> a 1.3964671 2.5511488 2.328294 1.761404 2.067044 1.096984 2.724748 2.003446 #> d 0.8271511 1.7493710 1.665183 2.032229 2.229795 1.492519 1.859688 2.324143 #> g 1.7126300 0.9099802 1.430696 1.744495 2.287378 2.823909 1.446341 1.304650 #> b 2.1387146 1.7622035 3.274496 1.500807 1.754657 1.708962 1.465679 1.772266 #> c 2.5422206 1.6452800 1.982620 1.611873 1.779726 1.445555 1.572318 1.816738 #> f 2.2530279 1.4161904 2.888542 1.944857 1.275898 2.281528 1.515743 1.923301 #> e 2.2145623 1.1854533 1.996198 2.479747 1.653140 1.918845 1.502830 3.035135 #> h 1.7266841 1.3295034 2.683914 1.544402 1.488172 1.613323 1.374007 1.638209 #> i 1.7177740 1.8528531 2.664782 1.581414 1.992431 2.802955 1.738086 2.129131 #> j 1.5549811 1.7670512 2.168236 3.207918 1.532026 1.421096 1.751575 1.841470 #>          i        j #> a 1.911105 1.973421 #> d 1.913106 2.500757 #> g 2.274999 1.432696 #> b 1.915003 2.127598 #> c 1.313849 2.852982 #> f 2.348804 2.177775 #> e 2.425116 1.752208 #> h 1.798634 2.439102 #> i 1.904203 2.486458 #> j 1.402736 3.060559  sample_class <- data.frame(grp = rep(c(\"grp1\", \"grp2\"), each = 5), stringsAsFactors = FALSE) rownames(sample_class) <- rownames(mat) neworder2 <- similarity_reorderbyclass(mat, sample_class[, \"grp\", drop = FALSE])  # if there is a class with only one member, it is dropped, with a warning sample_class[10, \"grp\"] = \"grp3\" neworder3 <- similarity_reorderbyclass(mat, sample_class[, \"grp\", drop = FALSE]) #> Warning: Removing groups: grp3 neworder3$indices # 10 should be missing #> [1] 1 4 5 2 3 6 8 7 9  mat[neworder2$indices, neworder2$indices] #>           a         d        e        b        c        i        j        g #> a 1.3964671 2.5511488 2.724748 1.761404 2.067044 1.911105 1.973421 2.328294 #> d 0.8271511 1.7493710 1.859688 2.032229 2.229795 1.913106 2.500757 1.665183 #> e 2.2145623 1.1854533 1.502830 2.479747 1.653140 2.425116 1.752208 1.996198 #> b 2.1387146 1.7622035 1.465679 1.500807 1.754657 1.915003 2.127598 3.274496 #> c 2.5422206 1.6452800 1.572318 1.611873 1.779726 1.313849 2.852982 1.982620 #> i 1.7177740 1.8528531 1.738086 1.581414 1.992431 1.904203 2.486458 2.664782 #> j 1.5549811 1.7670512 1.751575 3.207918 1.532026 1.402736 3.060559 2.168236 #> g 1.7126300 0.9099802 1.446341 1.744495 2.287378 2.274999 1.432696 1.430696 #> f 2.2530279 1.4161904 1.515743 1.944857 1.275898 2.348804 2.177775 2.888542 #> h 1.7266841 1.3295034 1.374007 1.544402 1.488172 1.798634 2.439102 2.683914 #>          f        h #> a 1.096984 2.003446 #> d 1.492519 2.324143 #> e 1.918845 3.035135 #> b 1.708962 1.772266 #> c 1.445555 1.816738 #> i 2.802955 2.129131 #> j 1.421096 1.841470 #> g 2.823909 1.304650 #> f 2.281528 1.923301 #> h 1.613323 1.638209 cbind(neworder$names, neworder2$names) #>       [,1] [,2] #>  [1,] \"a\"  \"a\"  #>  [2,] \"d\"  \"d\"  #>  [3,] \"g\"  \"e\"  #>  [4,] \"b\"  \"b\"  #>  [5,] \"c\"  \"c\"  #>  [6,] \"f\"  \"i\"  #>  [7,] \"e\"  \"j\"  #>  [8,] \"h\"  \"g\"  #>  [9,] \"i\"  \"f\"  #> [10,] \"j\"  \"h\""},{"path":"/reference/split_groups.html","id":null,"dir":"Reference","previous_headings":"","what":"split groups — split_groups","title":"split groups — split_groups","text":"Given matrix data.frame, character vector data.frame groups, splits indices / names matrix groups appropriately. function assumes matrix groups correct order!!","code":""},{"path":"/reference/split_groups.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"split groups — split_groups","text":"","code":"split_groups(in_matrix, groups = NULL)"},{"path":"/reference/split_groups.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"split groups — split_groups","text":"in_matrix matrix want split groups data.frame, character vector factor","code":""},{"path":"/reference/split_groups.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"split groups — split_groups","text":"list groups","code":""},{"path":"/reference/summarize_data.html","id":null,"dir":"Reference","previous_headings":"","what":"summarize data — summarize_data","title":"summarize data — summarize_data","text":"summarizes matrix data.frame, rows samples columns features","code":""},{"path":"/reference/summarize_data.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"summarize data — summarize_data","text":"","code":"summarize_data(   in_data,   sample_classes = NULL,   avg_function = mean,   log_transform = FALSE,   remove_zeros = FALSE )"},{"path":"/reference/summarize_data.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"summarize data — summarize_data","text":"in_data matrix data.frame sample_classes samples class avg_function function use summary log_transform apply log-transform mean remove_zeros remove zeros summarizing","code":""},{"path":"/reference/summarize_data.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"summarize data — summarize_data","text":"data.frame","code":""},{"path":"/reference/visqc_cor_pca_scores.html","id":null,"dir":"Reference","previous_headings":"","what":"correlate scores and outcome — visqc_cor_pca_scores","title":"correlate scores and outcome — visqc_cor_pca_scores","text":"Given matrix PCA scores, set sample attributes test, goes performs ICI-Kt scores versus attribute.","code":""},{"path":"/reference/visqc_cor_pca_scores.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"correlate scores and outcome — visqc_cor_pca_scores","text":"","code":"visqc_cor_pca_scores(pca_scores, sample_info)"},{"path":"/reference/visqc_cor_pca_scores.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"correlate scores and outcome — visqc_cor_pca_scores","text":"pca_scores scores matrix test sample_info data.frame sample attributes test Important: attributes must numeric, character.   character, transformed factor, numeric   factor levels used instead.   missing values present, OK, long   missing---random (.e. missing low end values).","code":""},{"path":"/reference/visqc_cor_pca_scores.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"correlate scores and outcome — visqc_cor_pca_scores","text":"data.frame","code":""},{"path":"/reference/visqc_heatmap.html","id":null,"dir":"Reference","previous_headings":"","what":"easier heatmaps — visqc_heatmap","title":"easier heatmaps — visqc_heatmap","text":"rolls common Heatmap options single function call make life easier creating lots heatmaps. Note: clustering rows columns disabled, expected reordering matrix beforehand, passing column_order row_order arguments passed Heatmap (see example). Matrices can reordered using similarity_reorderbyclass, nice class colors generated using generate_group_colors","code":""},{"path":"/reference/visqc_heatmap.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"easier heatmaps — visqc_heatmap","text":"","code":"visqc_heatmap(   matrix_data,   color_values,   title = \"\",   row_color_data = NULL,   row_color_list = NULL,   col_color_data = NULL,   col_color_list = NULL,   ... )"},{"path":"/reference/visqc_heatmap.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"easier heatmaps — visqc_heatmap","text":"matrix_data matrix want plot heatmap color_values color mapping values colors (see Details) title values represent row_color_data data row annotations row_color_list list row annotations col_color_data data column annotations col_color_list list column annotations ... Heatmap parameters","code":""},{"path":"/reference/visqc_heatmap.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"easier heatmaps — visqc_heatmap","text":"function uses ComplexHeatmap package produce heatmaps complex row- column-color annotations. row_color_data col_color_data data.frame's column describes meta-data rows columns matrix. row_color_list  col_color_list provide mapping color annotation, list entry named vector colors, list entry corresponding column entry data.frame, names colors corresponding annotations column.","code":""},{"path":"/reference/visqc_heatmap.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"easier heatmaps — visqc_heatmap","text":"","code":"if (FALSE) { library(circlize) data(grp_cor) data(grp_info) colormap <- colorRamp2(c(0, 1), c(\"black\", \"white\"))  annotation_color <- c(grp1 = \"green\", grp2 = \"red\", set1 = \"blue\",                       set2 = \"yellow\")  row_data <- grp_info[, \"grp\", drop = FALSE] col_data <- grp_info[, \"set\", drop = FALSE] row_annotation = list(grp = annotation_color[1:2]) col_annotation = list(set = annotation_color[3:4])  visqc_heatmap(grp_cor, colormap, row_color_data = row_data, row_color_list = row_annotation,                  col_color_data = col_data, col_color_list = col_annotation)                   reorder_sim <- similarity_reorderbyclass(grp_cor, transform = \"sub_1\") visqc_heatmap(grp_cor, colormap, \"reorder1\", row_data, row_annotation, col_data, col_annotation,                  column_order = reorder_sim$indices, row_order = reorder_sim$indices)  sample_classes <- grp_info[, \"grp\", drop = FALSE] reorder_sim2 <- similarity_reorderbyclass(grp_cor, sample_classes, \"sub_1\") visqc_heatmap(grp_cor, colormap, \"reorder2\", row_data, row_annotation, col_data, col_annotation,                  column_order = reorder_sim2$indices, row_order = reorder_sim2$indices) }"},{"path":"/reference/visqc_score_contributions.html","id":null,"dir":"Reference","previous_headings":"","what":"calculate pca contributions — visqc_score_contributions","title":"calculate pca contributions — visqc_score_contributions","text":"Given set PCA scores, calculates variance contributions, cumulative contributions, generates percent label can used labeling plots.","code":""},{"path":"/reference/visqc_score_contributions.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"calculate pca contributions — visqc_score_contributions","text":"","code":"visqc_score_contributions(pca_scores)"},{"path":"/reference/visqc_score_contributions.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"calculate pca contributions — visqc_score_contributions","text":"pca_scores matrix scores, columns PC","code":""},{"path":"/reference/visqc_score_contributions.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"calculate pca contributions — visqc_score_contributions","text":"data.frame","code":""},{"path":"/reference/visqc_test_pca_loadings.html","id":null,"dir":"Reference","previous_headings":"","what":"test loadings — visqc_test_pca_loadings","title":"test loadings — visqc_test_pca_loadings","text":"Given matrix loadings principal components, set components test, loading component, generates null distribution loadings components, reports p-value loading.","code":""},{"path":"/reference/visqc_test_pca_loadings.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"test loadings — visqc_test_pca_loadings","text":"","code":"visqc_test_pca_loadings(   loadings,   test_columns,   progress = FALSE,   direction = FALSE )"},{"path":"/reference/visqc_test_pca_loadings.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"test loadings — visqc_test_pca_loadings","text":"loadings matrix loadings pca decomposition test_columns names columns loadings test progress progress reported direction direction loading tested?","code":""},{"path":"/reference/visqc_test_pca_loadings.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"test loadings — visqc_test_pca_loadings","text":"named list","code":""},{"path":"/reference/visqc_test_pca_scores.html","id":null,"dir":"Reference","previous_headings":"","what":"test scores and outcome — visqc_test_pca_scores","title":"test scores and outcome — visqc_test_pca_scores","text":"Given matrix PCA scores, set sample attributes test, goes performs ANOVA scores versus attribute.","code":""},{"path":"/reference/visqc_test_pca_scores.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"test scores and outcome — visqc_test_pca_scores","text":"","code":"visqc_test_pca_scores(pca_scores, sample_info)"},{"path":"/reference/visqc_test_pca_scores.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"test scores and outcome — visqc_test_pca_scores","text":"pca_scores matrix scores PCA decomposition sample_info data.frame sample attributes test","code":""},{"path":"/reference/visqc_test_pca_scores.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"test scores and outcome — visqc_test_pca_scores","text":"data.frame","code":""},{"path":"/news/index.html","id":"visualizationqualitycontrol-0410","dir":"Changelog","previous_headings":"","what":"visualizationQualityControl 0.4.10","title":"visualizationQualityControl 0.4.10","text":"Updated quality_control vignette use ICIKendallTau instead correlation measures.","code":""},{"path":"/news/index.html","id":"visualizationqualitycontrol-049","dir":"Changelog","previous_headings":"","what":"visualizationQualityControl 0.4.9","title":"visualizationQualityControl 0.4.9","text":"Windows Mac binaries now available via r-universe, installation instructions updated reflect .","code":""},{"path":"/news/index.html","id":"visualizationqualitycontrol-047","dir":"Changelog","previous_headings":"","what":"visualizationQualityControl 0.4.7","title":"visualizationQualityControl 0.4.7","text":"Updated determine_outliers able use either output median_correlations outlier_fraction singly together. using one alone, suggest explicitly naming arguments correct entry set NULL one used. Updated README show using ici_kendalltau instead it_weighted_correlation. Updated tests, moved testthat v 3. Updated pkgdown rendering help site.","code":""},{"path":"/news/index.html","id":"visualizationqualitycontrol-040","dir":"Changelog","previous_headings":"","what":"visualizationQualityControl 0.4.0","title":"visualizationQualityControl 0.4.0","text":"Moving ICI-Kendall-tau code ’s package, ICIKendallTau. reduces dependencies necessary want run fast Kendall-tau.","code":""},{"path":"/news/index.html","id":"visualizationqualitycontrol-03100","dir":"Changelog","previous_headings":"","what":"visualizationQualityControl 0.3.100","title":"visualizationQualityControl 0.3.100","text":"Making splitup version ICI-Kendall-tau “implementation” (visqc_ici_kendallt), using single core user doesn’t setup “plan” first. reference version still exists can run tests , longer exported general users. Also inlined C++ sign function, gave us another 3X speedup 8 core machine larger test data set.","code":""},{"path":"/news/index.html","id":"visualizationqualitycontrol-0396","dir":"Changelog","previous_headings":"","what":"visualizationQualityControl 0.3.96","title":"visualizationQualityControl 0.3.96","text":"Now throw error X Y length ici_kendallt.","code":""},{"path":"/news/index.html","id":"visualizationqualitycontrol-0385","dir":"Changelog","previous_headings":"","what":"visualizationQualityControl 0.3.85","title":"visualizationQualityControl 0.3.85","text":"Added function calculating information-content-informed Kendall-tau correlation, ici_kendallt, variants around calculating pairwise correlations samples; visqc_ici_kendallt visqc_ici_kendallt_splitup parallel processing.","code":""},{"path":"/news/index.html","id":"visualizationqualitycontrol-0316","dir":"Changelog","previous_headings":"","what":"visualizationQualityControl 0.3.16","title":"visualizationQualityControl 0.3.16","text":"Removed requirement ggbiplot, instead added function calculating variances PCs scores. updated vignette accordingly. Now using globally_it_weighted_correlation locally_it_weighted_correlation instead pairwise_correlation.","code":""},{"path":"/news/index.html","id":"visualizationqualitycontrol-032","dir":"Changelog","previous_headings":"","what":"visualizationQualityControl 0.3.2","title":"visualizationQualityControl 0.3.2","text":"keep_non_zero_percentage gains argument, , defaults FALSE keep previous behavior. Setting = TRUE means value must non-zero least X% sample classes.","code":""},{"path":"/news/index.html","id":"visualizationqualitycontrol-030","dir":"Changelog","previous_headings":"","what":"visualizationQualityControl 0.3.0","title":"visualizationQualityControl 0.3.0","text":"median_correlations gains new argument, between_classes generate median values samples classes. causes appearance two columns set TRUE. default FALSE, hopefully cause current code misbehave, ’ve bumped version number warning.","code":""},{"path":"/news/index.html","id":"visualizationqualitycontrol-0218","dir":"Changelog","previous_headings":"","what":"visualizationQualityControl 0.2.18","title":"visualizationQualityControl 0.2.18","text":"Augmented correlations (weight = TRUE) much useful interpretable. information_volume correspondence calculations improved. Namely information_volume scaled maximum. correspondence default consider presence zeros samples informative, can changed setting not_both = TRUE. default useful cases lots features data sparse, zeros likely happen chance. addition returning cor matrix keep matrix, pairwise_correlations now returns raw correlations, weighting matrices info correspondence one can examined. diagonal info weighting corresponds many features sample compared sample features.","code":""},{"path":"/news/index.html","id":"visualizationqualitycontrol-025","dir":"Changelog","previous_headings":"","what":"visualizationQualityControl 0.2.5","title":"visualizationQualityControl 0.2.5","text":"Added two functions, information_volume correspondence calculate weights based amount things non-zero things pairwise correlation. Added logical argument weight pairwise_correlation weight correlations. weight = TRUE, diagonal 1 anymore, instead reflect many features total sample.","code":""},{"path":"/news/index.html","id":"visualizationqualitycontrol-023","dir":"Changelog","previous_headings":"","what":"visualizationQualityControl 0.2.3","title":"visualizationQualityControl 0.2.3","text":"bug discovered median_correlations meant wrong sample ids might added output data, making detection real problems difficult","code":""},{"path":"/news/index.html","id":"visualizationqualitycontrol-021","dir":"Changelog","previous_headings":"","what":"visualizationQualityControl 0.2.1","title":"visualizationQualityControl 0.2.1","text":"pairwise_correlation now uses cor internally directly, whereas previously loop allow pairwise comparisons. makes correlations 3x faster. count removed list returned pairwise_correlation new function pairwise_correlation_count get counts pairwise comparison","code":""},{"path":"/news/index.html","id":"visualizationqualitycontrol-011","dir":"Changelog","previous_headings":"","what":"visualizationQualityControl 0.1.1","title":"visualizationQualityControl 0.1.1","text":"Changed correlation function return list instead matrix. list contains correlations (cor), counts correlation (count), points passed criteria (keep).","code":""}]
